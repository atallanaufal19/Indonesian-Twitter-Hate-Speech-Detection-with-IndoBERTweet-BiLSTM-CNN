{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y97QhcmWjQRf"
      },
      "source": [
        "#**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lxj5H6igX4Rs",
        "outputId": "6ba75c9c-5112-4df8-a45f-0073865ff97e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>HS</th>\n",
              "      <th>stemmed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disaat semua cowok berusaha melacak perhatian ...</td>\n",
              "      <td>1</td>\n",
              "      <td>saat semua cowok usaha lacak perhatiangue loe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>siapa yang telat ngasih tau eluedan sarap gue ...</td>\n",
              "      <td>0</td>\n",
              "      <td>siapa yang telat ngasih tau eluedan sarap gue ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kadang aku berfikir kenapa aku tetap percaya ...</td>\n",
              "      <td>0</td>\n",
              "      <td>kadang aku berfikir kenapa aku tetap percaya p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aku itu akunnku tau matamu sipit tapi diliat d...</td>\n",
              "      <td>0</td>\n",
              "      <td>aku itu akunnku tau mata sipit tapi liat dari ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kaum cebong kapir udah keliatan dongoknya dari...</td>\n",
              "      <td>1</td>\n",
              "      <td>kaum cebong kapir udah liat dongok dari awal t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ya bani taplak dkk</td>\n",
              "      <td>1</td>\n",
              "      <td>ya bani taplak dkk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>deklarasi pilkada  aman dan anti hoax warga du...</td>\n",
              "      <td>0</td>\n",
              "      <td>deklarasi pilkada aman dan anti hoax warga duk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gue baru aja kelar rewatch aldnoah zero paling...</td>\n",
              "      <td>0</td>\n",
              "      <td>gue baru aja kelar rewatch aldnoah zero paling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>nah admin belanja satu lagi poterbaik nak maka...</td>\n",
              "      <td>0</td>\n",
              "      <td>nah admin belanja satu lagi poterbaik nak maka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>enak lg klo smbil ngewe</td>\n",
              "      <td>0</td>\n",
              "      <td>enak lg klo smbil ngewe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  HS  \\\n",
              "0  disaat semua cowok berusaha melacak perhatian ...   1   \n",
              "1  siapa yang telat ngasih tau eluedan sarap gue ...   0   \n",
              "2   kadang aku berfikir kenapa aku tetap percaya ...   0   \n",
              "3  aku itu akunnku tau matamu sipit tapi diliat d...   0   \n",
              "4  kaum cebong kapir udah keliatan dongoknya dari...   1   \n",
              "5                                ya bani taplak dkk    1   \n",
              "6  deklarasi pilkada  aman dan anti hoax warga du...   0   \n",
              "7  gue baru aja kelar rewatch aldnoah zero paling...   0   \n",
              "8  nah admin belanja satu lagi poterbaik nak maka...   0   \n",
              "9                            enak lg klo smbil ngewe   0   \n",
              "\n",
              "                                       stemmed_tweet  \n",
              "0  saat semua cowok usaha lacak perhatiangue loe ...  \n",
              "1  siapa yang telat ngasih tau eluedan sarap gue ...  \n",
              "2  kadang aku berfikir kenapa aku tetap percaya p...  \n",
              "3  aku itu akunnku tau mata sipit tapi liat dari ...  \n",
              "4  kaum cebong kapir udah liat dongok dari awal t...  \n",
              "5                                 ya bani taplak dkk  \n",
              "6  deklarasi pilkada aman dan anti hoax warga duk...  \n",
              "7  gue baru aja kelar rewatch aldnoah zero paling...  \n",
              "8  nah admin belanja satu lagi poterbaik nak maka...  \n",
              "9                            enak lg klo smbil ngewe  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('stemmed_tweets.csv', encoding='ISO-8859-1')\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbzXqz9_X659",
        "outputId": "605e54b5-a0c7-4f38-e6a2-62affc091f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tweet            0\n",
              "HS               0\n",
              "stemmed_tweet    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna(subset=['stemmed_tweet'])\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP1pS0FXYWGp",
        "outputId": "a461b9d4-ba2c-4a36-a650-91752878174f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Tweet  HS  \\\n",
            "0  disaat semua cowok berusaha melacak perhatian ...   1   \n",
            "1  siapa yang telat ngasih tau eluedan sarap gue ...   0   \n",
            "2   kadang aku berfikir kenapa aku tetap percaya ...   0   \n",
            "3  aku itu akunnku tau matamu sipit tapi diliat d...   0   \n",
            "4  kaum cebong kapir udah keliatan dongoknya dari...   1   \n",
            "5                                ya bani taplak dkk    1   \n",
            "6  deklarasi pilkada  aman dan anti hoax warga du...   0   \n",
            "7  gue baru aja kelar rewatch aldnoah zero paling...   0   \n",
            "8  nah admin belanja satu lagi poterbaik nak maka...   0   \n",
            "9                            enak lg klo smbil ngewe   0   \n",
            "\n",
            "                                       stemmed_tweet  \\\n",
            "0  saat semua cowok usaha lacak perhatiangue loe ...   \n",
            "1  siapa yang telat ngasih tau eluedan sarap gue ...   \n",
            "2  kadang aku berfikir kenapa aku tetap percaya p...   \n",
            "3  aku itu akunnku tau mata sipit tapi liat dari ...   \n",
            "4  kaum cebong kapir udah liat dongok dari awal t...   \n",
            "5                                 ya bani taplak dkk   \n",
            "6  deklarasi pilkada aman dan anti hoax warga duk...   \n",
            "7  gue baru aja kelar rewatch aldnoah zero paling...   \n",
            "8  nah admin belanja satu lagi poterbaik nak maka...   \n",
            "9                            enak lg klo smbil ngewe   \n",
            "\n",
            "                                        no_stopwords  \n",
            "0  cowok usaha lacak perhatiangue loe lantas reme...  \n",
            "1  telat ngasih tau eluedan sarap gue gaul cigax ...  \n",
            "2  kadang berfikir percaya tuhan jatuh berkalikal...  \n",
            "3                        akunnku tau mata sipit liat  \n",
            "4  kaum cebong kapir udah liat dongok dongok hahahah  \n",
            "5                                 ya bani taplak dkk  \n",
            "6  deklarasi pilkada aman anti hoax warga dukuh s...  \n",
            "7  gue aja kelar rewatch aldnoah zero kampret ema...  \n",
            "8  admin belanja poterbaik nak makan ais kepal mi...  \n",
            "9                            enak lg klo smbil ngewe  \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Make sure to download these resources if you haven't already\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load Indonesian stopwords\n",
        "indonesian_stopwords = stopwords.words('indonesian')\n",
        "\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word not in indonesian_stopwords]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to each tweet\n",
        "df['no_stopwords'] = df['stemmed_tweet'].apply(remove_stopwords)\n",
        "\n",
        "# Display the first 10 rows of the DataFrame to check the result\n",
        "print(df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving the DataFrame to a CSV file\n",
        "df.to_csv('final_Process_Tweet.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qQJSrJEPYrsA",
        "outputId": "e8f02385-b2ee-409a-e798-98447590c087"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HS</th>\n",
              "      <th>no_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cowok usaha lacak perhatiangue loe lantas reme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>telat ngasih tau eluedan sarap gue gaul cigax ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>kadang berfikir percaya tuhan jatuh berkalikal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>akunnku tau mata sipit liat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>kaum cebong kapir udah liat dongok dongok hahahah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13131</th>\n",
              "      <td>1</td>\n",
              "      <td>cina antek aseng emang suka bikin rusak negara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13132</th>\n",
              "      <td>1</td>\n",
              "      <td>mikir ga banyakan orang biadab orang islam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13133</th>\n",
              "      <td>1</td>\n",
              "      <td>goblok banget nih orang udah tau salah playing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13134</th>\n",
              "      <td>1</td>\n",
              "      <td>orang orang kayak gini nih pantes mati gedek b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13135</th>\n",
              "      <td>1</td>\n",
              "      <td>si budha damai myanmar hobi bantai orang islam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13123 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       HS                                       no_stopwords\n",
              "0       1  cowok usaha lacak perhatiangue loe lantas reme...\n",
              "1       0  telat ngasih tau eluedan sarap gue gaul cigax ...\n",
              "2       0  kadang berfikir percaya tuhan jatuh berkalikal...\n",
              "3       0                        akunnku tau mata sipit liat\n",
              "4       1  kaum cebong kapir udah liat dongok dongok hahahah\n",
              "...    ..                                                ...\n",
              "13131   1  cina antek aseng emang suka bikin rusak negara...\n",
              "13132   1         mikir ga banyakan orang biadab orang islam\n",
              "13133   1  goblok banget nih orang udah tau salah playing...\n",
              "13134   1  orang orang kayak gini nih pantes mati gedek b...\n",
              "13135   1     si budha damai myanmar hobi bantai orang islam\n",
              "\n",
              "[13123 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[['HS', 'no_stopwords']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1tCamoF7b7"
      },
      "source": [
        "#**indobertweet-bilstm-cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODNI2MNWSPXa",
        "outputId": "bba7d029-ea86-4c7e-c39e-97a9ccbce3c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 100, 768)          24516864  \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 100, 256)          918528    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 100, 256)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 96, 128)           163968    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 48, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 46, 64)            24640     \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 23, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1472)              0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 1473      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25625473 (97.75 MB)\n",
            "Trainable params: 1108609 (4.23 MB)\n",
            "Non-trainable params: 24516864 (93.52 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 174s 1s/step - loss: 0.5715 - accuracy: 0.6817 - val_loss: 0.4631 - val_accuracy: 0.7665\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 167s 1s/step - loss: 0.3983 - accuracy: 0.8200 - val_loss: 0.3842 - val_accuracy: 0.8225\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 171s 1s/step - loss: 0.3461 - accuracy: 0.8468 - val_loss: 0.4117 - val_accuracy: 0.8095\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 172s 1s/step - loss: 0.3177 - accuracy: 0.8604 - val_loss: 0.4419 - val_accuracy: 0.8034\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 171s 1s/step - loss: 0.2909 - accuracy: 0.8750 - val_loss: 0.3571 - val_accuracy: 0.8400\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 165s 997ms/step - loss: 0.2636 - accuracy: 0.8859 - val_loss: 0.3609 - val_accuracy: 0.8350\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 172s 1s/step - loss: 0.2344 - accuracy: 0.9016 - val_loss: 0.3734 - val_accuracy: 0.8442\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 165s 1s/step - loss: 0.1975 - accuracy: 0.9179 - val_loss: 0.4870 - val_accuracy: 0.8088\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f12ec493070>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Conv1D(64, kernel_size=3, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D())\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Qf6YZhX3TR",
        "outputId": "de83681a-d948-44ed-b01d-20f397834829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83/83 [==============================] - 18s 210ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8455    0.8882    0.8663      1503\n",
            "           1     0.8394    0.7825    0.8100      1122\n",
            "\n",
            "    accuracy                         0.8430      2625\n",
            "   macro avg     0.8424    0.8354    0.8381      2625\n",
            "weighted avg     0.8429    0.8430    0.8422      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63yk8mmHo6QM",
        "outputId": "0567419a-ceda-4d72-9c30-b91df7323ed1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model_combined.save('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xegqP0qJpNv2",
        "outputId": "9eff9091-4cec-43a2-b4dc-7eb7e6481703"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1b6c05da-46e1-4815-b39d-c9b6233cd6c3\", \"trained_model.h5\", 113796440)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('trained_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlXUB0wwFm_E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTsWT5utTp9",
        "outputId": "3204a8f2-6e53-479e-9516-fac8e3f70dfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13219, 2)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7tiS_erlKr5"
      },
      "source": [
        "#**BiLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLDrPWQJlS9d",
        "outputId": "eb679686-3ece-4243-a8ba-ead3eba6fee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 97ms/step - accuracy: 0.6899 - loss: 0.5535 - val_accuracy: 0.8519 - val_loss: 0.3165\n",
            "Epoch 2/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 95ms/step - accuracy: 0.9325 - loss: 0.1771 - val_accuracy: 0.8438 - val_loss: 0.3538\n",
            "Epoch 3/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 89ms/step - accuracy: 0.9717 - loss: 0.0839 - val_accuracy: 0.8371 - val_loss: 0.4731\n",
            "Epoch 4/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 97ms/step - accuracy: 0.9853 - loss: 0.0439 - val_accuracy: 0.8376 - val_loss: 0.5618\n",
            "Epoch 5/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 100ms/step - accuracy: 0.9908 - loss: 0.0259 - val_accuracy: 0.8348 - val_loss: 0.6301\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative     0.8367    0.8523    0.8444      1503\n",
            "    Positive     0.7971    0.7772    0.7870      1122\n",
            "\n",
            "    accuracy                         0.8202      2625\n",
            "   macro avg     0.8169    0.8147    0.8157      2625\n",
            "weighted avg     0.8198    0.8202    0.8199      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Membagi data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['no_stopwords'], df['HS'], test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Vektorisasi teks dengan Tokenizer dan pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_vect = pad_sequences(X_train_seq, maxlen=100)  # Sesuaikan maxlen sesuai kebutuhan\n",
        "\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_vect = pad_sequences(X_val_seq, maxlen=100)\n",
        "\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_vect = pad_sequences(X_test_seq, maxlen=100)\n",
        "\n",
        "# Pembuatan model\n",
        "model_bilstm = Sequential()\n",
        "model_bilstm.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, trainable=True))\n",
        "model_bilstm.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_bilstm.add(GlobalMaxPooling1D())\n",
        "model_bilstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Kompilasi model\n",
        "model_bilstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Pelatihan model\n",
        "history = model_bilstm.fit(X_train_vect, y_train, epochs=5, batch_size=16, validation_data=(X_val_vect, y_val), verbose=1)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model_bilstm.predict(X_test_vect)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred_labels, target_names=['Negative', 'Positive'], digits=4)\n",
        "print(report)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_vkKJX7GQ74"
      },
      "source": [
        "#**cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kLKYHgARzY2",
        "outputId": "2e114669-3710-45f8-958a-214eefd07dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.6810 - loss: 0.5561 - val_accuracy: 0.8004 - val_loss: 0.4166\n",
            "Epoch 2/5\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.9163 - loss: 0.2152 - val_accuracy: 0.8095 - val_loss: 0.4566\n",
            "Epoch 3/5\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9690 - loss: 0.0767 - val_accuracy: 0.8156 - val_loss: 0.6072\n",
            "Epoch 4/5\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9843 - loss: 0.0385 - val_accuracy: 0.8076 - val_loss: 0.7037\n",
            "Epoch 5/5\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9896 - loss: 0.0237 - val_accuracy: 0.8069 - val_loss: 0.8833\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.81      0.84      0.82      1503\n",
            "    Positive       0.77      0.74      0.75      1122\n",
            "\n",
            "    accuracy                           0.79      2625\n",
            "   macro avg       0.79      0.79      0.79      2625\n",
            "weighted avg       0.79      0.79      0.79      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Membagi data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['no_stopwords'], df['HS'], test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Vektorisasi teks\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_vect = pad_sequences(X_train_seq, maxlen=100)  # Sesuaikan maxlen sesuai kebutuhan\n",
        "\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_vect = pad_sequences(X_val_seq, maxlen=100)\n",
        "\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_vect = pad_sequences(X_test_seq, maxlen=100)\n",
        "\n",
        "# Pembuatan model CNN\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, trainable=True))\n",
        "model_cnn.add(Conv1D(128, 5, activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(5))\n",
        "model_cnn.add(Conv1D(64, 3, activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Kompilasi model\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Pelatihan model\n",
        "history = model_cnn.fit(X_train_vect, y_train, epochs=5, batch_size=16, validation_data=(X_val_vect, y_val), verbose=1)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model_cnn.predict(X_test_vect)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred_labels, target_names=['Negative', 'Positive'])\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative     0.8095    0.8370    0.8230      1503\n",
            "    Positive     0.7712    0.7362    0.7533      1122\n",
            "\n",
            "    accuracy                         0.7939      2625\n",
            "   macro avg     0.7904    0.7866    0.7882      2625\n",
            "weighted avg     0.7932    0.7939    0.7932      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prediksi\n",
        "y_pred = model_cnn.predict(X_test_vect)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred_labels, target_names=['Negative', 'Positive'], digits=4)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QbAaWQwGT1e"
      },
      "source": [
        "#**bilstm-cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dnctxSlShnB",
        "outputId": "0920e3e2-034b-4baf-d399-00cb0443533d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 113ms/step - accuracy: 0.7120 - loss: 0.5198 - val_accuracy: 0.8519 - val_loss: 0.3436\n",
            "Epoch 2/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 112ms/step - accuracy: 0.9324 - loss: 0.1667 - val_accuracy: 0.8305 - val_loss: 0.4413\n",
            "Epoch 3/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 109ms/step - accuracy: 0.9688 - loss: 0.0845 - val_accuracy: 0.8319 - val_loss: 0.5167\n",
            "Epoch 4/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 110ms/step - accuracy: 0.9822 - loss: 0.0460 - val_accuracy: 0.8252 - val_loss: 0.7706\n",
            "Epoch 5/5\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 111ms/step - accuracy: 0.9894 - loss: 0.0281 - val_accuracy: 0.8224 - val_loss: 0.9562\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative     0.8342    0.8270    0.8306      1503\n",
            "    Positive     0.7709    0.7799    0.7754      1122\n",
            "\n",
            "    accuracy                         0.8069      2625\n",
            "   macro avg     0.8026    0.8034    0.8030      2625\n",
            "weighted avg     0.8072    0.8069    0.8070      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Membagi data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['no_stopwords'], df['HS'], test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Vektorisasi teks\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_vect = pad_sequences(X_train_seq, maxlen=100)  # Sesuaikan maxlen sesuai kebutuhan\n",
        "\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_vect = pad_sequences(X_val_seq, maxlen=100)\n",
        "\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_vect = pad_sequences(X_test_seq, maxlen=100)\n",
        "\n",
        "# Pembuatan model CNN\n",
        "model_bilstm_cnn = Sequential()\n",
        "model_bilstm_cnn.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, trainable=True))\n",
        "model_bilstm_cnn.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_bilstm_cnn.add(Conv1D(128, 5, activation='relu'))\n",
        "model_bilstm_cnn.add(MaxPooling1D(2))\n",
        "model_bilstm_cnn.add(Conv1D(64, 3, activation='relu'))\n",
        "model_bilstm_cnn.add(GlobalMaxPooling1D())\n",
        "model_bilstm_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Kompilasi model\n",
        "model_bilstm_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Pelatihan model\n",
        "history = model_bilstm_cnn.fit(X_train_vect, y_train, epochs=5, batch_size=16, validation_data=(X_val_vect, y_val), verbose=1)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model_bilstm_cnn.predict(X_test_vect)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Laporan klasifikasi\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred_labels, target_names=['Negative', 'Positive'], digits=4)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 164ms/step - accuracy: 0.5582 - loss: 0.7020 - val_accuracy: 0.5800 - val_loss: 0.6687\n",
            "Epoch 2/100\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 160ms/step - accuracy: 0.5749 - loss: 0.6626 - val_accuracy: 0.6890 - val_loss: 0.6021\n",
            "Epoch 3/100\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 156ms/step - accuracy: 0.5810 - loss: 0.6614 - val_accuracy: 0.5800 - val_loss: 0.6805\n",
            "Epoch 4/100\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 154ms/step - accuracy: 0.5836 - loss: 0.6796 - val_accuracy: 0.5800 - val_loss: 0.6822\n",
            "Epoch 5/100\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 152ms/step - accuracy: 0.5740 - loss: 0.6827 - val_accuracy: 0.5800 - val_loss: 0.6804\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6609    0.9527    0.7804      1522\n",
            "           1     0.8326    0.3249    0.4674      1102\n",
            "\n",
            "    accuracy                         0.6890      2624\n",
            "   macro avg     0.7467    0.6388    0.6239      2624\n",
            "weighted avg     0.7330    0.6890    0.6489      2624\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is loaded and prepared\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the improved model\n",
        "indobertwwet = Sequential()\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "indobertwwet.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "indobertwwet.add(Flatten())  # Flatten the output of the embedding to collapse the sequence dimension\n",
        "indobertwwet.add(Dense(128, activation='relu'))\n",
        "indobertwwet.add(Dense(128, activation='relu'))\n",
        "indobertwwet.add(Dense(128, activation='relu'))\n",
        "indobertwwet.add(Dense(128, activation='relu'))\n",
        "indobertwwet.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "indobertwwet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "indobertwwet.summary()\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "indobertwwet.fit(X_train, y_train, epochs=100, batch_size=3, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Predictions\n",
        "y_pred = indobertwwet.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'tf_bert_model' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_bert_model' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 100), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Build and summarize the model\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m indobertweet_enhanced \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m indobertweet_enhanced\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Define EarlyStopping callback\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[1], line 41\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Using the transformer model's output\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_indobertweet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the last hidden state\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Multihead Attention\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:566\u001b[0m, in \u001b[0;36minput_processing\u001b[1;34m(func, config, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m         output[main_input_name] \u001b[38;5;241m=\u001b[39m main_input\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 566\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(main_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_input_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m         )\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Populates any unspecified argument with their default value, according to the signature.\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m parameter_names:\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_bert_model' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, 100), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, LayerNormalization, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('final_Process_Tweet.csv')\n",
        "df.dropna(subset=['no_stopwords'], inplace=True)  # Drop rows with NaN in 'no_stopwords'\n",
        "df['no_stopwords'] = df['no_stopwords'].astype(str)  # Ensure all data are strings\n",
        "\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding='max_length', truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model with Multihead Attention\n",
        "def create_model():\n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
        "    \n",
        "    # Using the transformer model's output\n",
        "    outputs = model_indobertweet(input_ids=input_ids)\n",
        "    sequence_output = outputs[0]  # Get the last hidden state\n",
        "\n",
        "    # Multihead Attention\n",
        "    attn_output = MultiHeadAttention(num_heads=2, key_dim=model_indobertweet.config.hidden_size)(sequence_output, sequence_output)\n",
        "    x = LayerNormalization(epsilon=1e-6)(sequence_output + attn_output)\n",
        "\n",
        "    # Feed Forward Network\n",
        "    ff_output = Dense(model_indobertweet.config.hidden_size, activation='relu')(x)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Mean pooling\n",
        "    x = tf.reduce_mean(x, axis=1)\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=[input_ids], outputs=[output])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Build and summarize the model\n",
        "indobertweet_enhanced = create_model()\n",
        "indobertweet_enhanced.summary()\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "indobertweet_enhanced.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Predictions\n",
        "y_pred = indobertweet_enhanced.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkGXMBiSGWTz"
      },
      "source": [
        "#**indobertwwet-bilstm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX_z0MlATTsQ",
        "outputId": "df668880-d925-4cbc-b472-fa83b0147ff7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_45\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_45\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_32                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_32 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_32                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 130ms/step - accuracy: 0.6851 - loss: 0.5784 - val_accuracy: 0.8206 - val_loss: 0.4083\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 120ms/step - accuracy: 0.8336 - loss: 0.3674 - val_accuracy: 0.8430 - val_loss: 0.3507\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 117ms/step - accuracy: 0.8632 - loss: 0.3124 - val_accuracy: 0.8476 - val_loss: 0.3446\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 118ms/step - accuracy: 0.8803 - loss: 0.2764 - val_accuracy: 0.8446 - val_loss: 0.3671\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 126ms/step - accuracy: 0.9045 - loss: 0.2287 - val_accuracy: 0.8450 - val_loss: 0.3610\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 120ms/step - accuracy: 0.9257 - loss: 0.1910 - val_accuracy: 0.8430 - val_loss: 0.3832\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8621    0.8736    0.8678      1503\n",
            "           1     0.8276    0.8128    0.8201      1122\n",
            "\n",
            "    accuracy                         0.8476      2625\n",
            "   macro avg     0.8449    0.8432    0.8440      2625\n",
            "weighted avg     0.8474    0.8476    0.8474      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the improved model using the name 'model_indobertweet_bilstm'\n",
        "model_indobertweet_bilstm = Sequential()\n",
        "model_indobertweet_bilstm.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=model_indobertweet.config.hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_indobertweet_bilstm.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "model_indobertweet_bilstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model_indobertweet_bilstm.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_indobertweet_bilstm.summary()\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model_indobertweet_bilstm.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_indobertweet_bilstm.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19nMk-W7GdKv"
      },
      "source": [
        "#**indobertweet-cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQTZ9d7CYtxF",
        "outputId": "592317f5-8d5f-4c7e-c098-41cf6581d641"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_50\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_50\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_37 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_35 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.7242 - loss: 0.5286 - val_accuracy: 0.8076 - val_loss: 0.4254\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 44ms/step - accuracy: 0.9093 - loss: 0.2325 - val_accuracy: 0.8385 - val_loss: 0.3671\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 46ms/step - accuracy: 0.9712 - loss: 0.0937 - val_accuracy: 0.8446 - val_loss: 0.4622\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 44ms/step - accuracy: 0.9891 - loss: 0.0401 - val_accuracy: 0.8427 - val_loss: 0.5486\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 47ms/step - accuracy: 0.9956 - loss: 0.0200 - val_accuracy: 0.8381 - val_loss: 0.6778\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9172    0.7891    0.8484      1503\n",
            "           1     0.7620    0.9046    0.8272      1122\n",
            "\n",
            "    accuracy                         0.8385      2625\n",
            "   macro avg     0.8396    0.8469    0.8378      2625\n",
            "weighted avg     0.8509    0.8385    0.8393      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['stemmed_tweet'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model using the name 'model_indobertweet_cnn'\n",
        "model_indobertweet_cnn = Sequential()\n",
        "model_indobertweet_cnn.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=model_indobertweet.config.hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_indobertweet_cnn.add(Conv1D(128, kernel_size=5, activation='relu', padding='valid'))\n",
        "model_indobertweet_cnn.add(MaxPooling1D(2))\n",
        "model_indobertweet_cnn.add(Conv1D(64, kernel_size=3, activation='relu', padding='valid'))\n",
        "model_indobertweet_cnn.add(GlobalMaxPooling1D())\n",
        "#model_indobertweet_cnn.add(Dense(128, activation='relu'))\n",
        "\n",
        "#model_indobertweet_cnn.add(Dropout(0.5))\n",
        "#model_indobertweet_cnn.add(Dense(64, activation='relu'))\n",
        "model_indobertweet_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_indobertweet_cnn.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_indobertweet_cnn.summary()\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model_indobertweet_cnn.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_indobertweet_cnn.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MAy-Nd3ey2G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anKvib_RhLNF"
      },
      "source": [
        "#**Batch Size and Learningrate Experient**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 297ms/step - accuracy: 0.6901 - loss: 0.5669 - val_accuracy: 0.8400 - val_loss: 0.3650\n",
            "Epoch 2/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 269ms/step - accuracy: 0.8405 - loss: 0.3496 - val_accuracy: 0.8404 - val_loss: 0.3643\n",
            "Epoch 3/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 255ms/step - accuracy: 0.8739 - loss: 0.2921 - val_accuracy: 0.8453 - val_loss: 0.3592\n",
            "Epoch 4/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 268ms/step - accuracy: 0.9018 - loss: 0.2372 - val_accuracy: 0.8389 - val_loss: 0.3729\n",
            "Epoch 5/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 296ms/step - accuracy: 0.9236 - loss: 0.1862 - val_accuracy: 0.8217 - val_loss: 0.5380\n",
            "Epoch 6/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 281ms/step - accuracy: 0.9492 - loss: 0.1270 - val_accuracy: 0.8408 - val_loss: 0.4397\n",
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 357ms/step - accuracy: 0.6547 - loss: 0.5961 - val_accuracy: 0.7741 - val_loss: 0.4915\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 333ms/step - accuracy: 0.8479 - loss: 0.3499 - val_accuracy: 0.8316 - val_loss: 0.3671\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 429ms/step - accuracy: 0.8668 - loss: 0.3049 - val_accuracy: 0.8442 - val_loss: 0.3501\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 434ms/step - accuracy: 0.8912 - loss: 0.2562 - val_accuracy: 0.8415 - val_loss: 0.3803\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 434ms/step - accuracy: 0.9176 - loss: 0.2048 - val_accuracy: 0.8423 - val_loss: 0.3819\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 398ms/step - accuracy: 0.9370 - loss: 0.1555 - val_accuracy: 0.8362 - val_loss: 0.4401\n",
            "Epoch 1/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 457ms/step - accuracy: 0.6398 - loss: 0.6064 - val_accuracy: 0.8248 - val_loss: 0.4077\n",
            "Epoch 2/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 390ms/step - accuracy: 0.8286 - loss: 0.3757 - val_accuracy: 0.8324 - val_loss: 0.3639\n",
            "Epoch 3/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 385ms/step - accuracy: 0.8629 - loss: 0.3126 - val_accuracy: 0.8377 - val_loss: 0.3790\n",
            "Epoch 1/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 617ms/step - accuracy: 0.6489 - loss: 0.6147 - val_accuracy: 0.7905 - val_loss: 0.4492\n",
            "Epoch 2/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 595ms/step - accuracy: 0.8217 - loss: 0.3900 - val_accuracy: 0.8210 - val_loss: 0.3971\n",
            "Epoch 3/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 611ms/step - accuracy: 0.8507 - loss: 0.3441 - val_accuracy: 0.8274 - val_loss: 0.3746\n",
            "Epoch 1/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 385ms/step - accuracy: 0.5875 - loss: 0.6602 - val_accuracy: 0.8000 - val_loss: 0.4380\n",
            "Epoch 2/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 372ms/step - accuracy: 0.8002 - loss: 0.4253 - val_accuracy: 0.8183 - val_loss: 0.4046\n",
            "Epoch 3/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 371ms/step - accuracy: 0.8316 - loss: 0.3758 - val_accuracy: 0.8255 - val_loss: 0.3857\n",
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 491ms/step - accuracy: 0.5807 - loss: 0.6707 - val_accuracy: 0.7989 - val_loss: 0.4486\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 486ms/step - accuracy: 0.8000 - loss: 0.4428 - val_accuracy: 0.7859 - val_loss: 0.4619\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 487ms/step - accuracy: 0.8172 - loss: 0.3988 - val_accuracy: 0.7570 - val_loss: 0.4829\n",
            "Epoch 1/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 520ms/step - accuracy: 0.5761 - loss: 0.6772 - val_accuracy: 0.6408 - val_loss: 0.6215\n",
            "Epoch 2/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 513ms/step - accuracy: 0.7376 - loss: 0.5274 - val_accuracy: 0.7787 - val_loss: 0.4513\n",
            "Epoch 3/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 516ms/step - accuracy: 0.8004 - loss: 0.4243 - val_accuracy: 0.8149 - val_loss: 0.4122\n",
            "Epoch 1/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.5676 - loss: 0.6792 - val_accuracy: 0.6495 - val_loss: 0.6681\n",
            "Epoch 2/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 1s/step - accuracy: 0.6148 - loss: 0.6473 - val_accuracy: 0.7775 - val_loss: 0.4775\n",
            "Epoch 3/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 1s/step - accuracy: 0.7747 - loss: 0.4744 - val_accuracy: 0.8011 - val_loss: 0.4263\n",
            "Epoch 1/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 421ms/step - accuracy: 0.5749 - loss: 0.6811 - val_accuracy: 0.5726 - val_loss: 0.6780\n",
            "Epoch 2/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 407ms/step - accuracy: 0.5747 - loss: 0.6756 - val_accuracy: 0.5726 - val_loss: 0.6714\n",
            "Epoch 3/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 401ms/step - accuracy: 0.5788 - loss: 0.6692 - val_accuracy: 0.6583 - val_loss: 0.6678\n",
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 546ms/step - accuracy: 0.5545 - loss: 0.6858 - val_accuracy: 0.5726 - val_loss: 0.6810\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 544ms/step - accuracy: 0.5744 - loss: 0.6756 - val_accuracy: 0.5726 - val_loss: 0.6759\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10469s\u001b[0m 16s/step - accuracy: 0.5725 - loss: 0.6721 - val_accuracy: 0.5752 - val_loss: 0.6720\n",
            "Epoch 1/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 336ms/step - accuracy: 0.5578 - loss: 0.6850 - val_accuracy: 0.5726 - val_loss: 0.6833\n",
            "Epoch 2/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 315ms/step - accuracy: 0.5784 - loss: 0.6771 - val_accuracy: 0.5726 - val_loss: 0.6776\n",
            "Epoch 3/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 321ms/step - accuracy: 0.5820 - loss: 0.6740 - val_accuracy: 0.5783 - val_loss: 0.6774\n",
            "Epoch 1/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 558ms/step - accuracy: 0.5337 - loss: 0.6902 - val_accuracy: 0.5726 - val_loss: 0.6809\n",
            "Epoch 2/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 539ms/step - accuracy: 0.5789 - loss: 0.6791 - val_accuracy: 0.5726 - val_loss: 0.6788\n",
            "Epoch 3/50\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 540ms/step - accuracy: 0.5663 - loss: 0.6804 - val_accuracy: 0.5726 - val_loss: 0.6770\n",
            "    lr 0.001 lr 0.0001  lr 1e-05\n",
            "10  0.840762  0.825524  0.658286\n",
            "16   0.83619  0.756952  0.575238\n",
            "32  0.837714  0.814857  0.578286\n",
            "64  0.827429  0.801143  0.572571\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of learning rates and batch sizes to experiment with\n",
        "learning_rates = [0.001, 0.0001, 0.00001]\n",
        "batch_sizes = [10, 16, 32, 64]\n",
        "\n",
        "# Create a table to store val_accuracy results\n",
        "val_accuracy_table = pd.DataFrame(index=batch_sizes, columns=[f\"lr {lr}\" for lr in learning_rates])\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Loop through learning rates\n",
        "for lr in learning_rates:\n",
        "    # Loop through batch sizes\n",
        "    for batch_size in batch_sizes:\n",
        "        # Create and compile the model with specified learning rate and batch size\n",
        "        model_combined = Sequential()\n",
        "        hidden_size = model_indobertweet.config.hidden_size\n",
        "        model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "        model_combined.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "        model_combined.add(Dropout(0.5))\n",
        "        model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "        model_combined.add(MaxPooling1D(pool_size=2))\n",
        "        model_combined.add(Flatten())\n",
        "        model_combined.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "        model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        history = model_combined.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "        # Save val_accuracy in the table\n",
        "        val_accuracy_table.loc[batch_size, f\"lr {lr}\"] = history.history['val_accuracy'][-1]\n",
        "\n",
        "# Display the val_accuracy table\n",
        "print(val_accuracy_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 318ms/step - accuracy: 0.6717 - loss: 0.5759 - val_accuracy: 0.8293 - val_loss: 0.3681\n",
            "Epoch 2/50\n",
            "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 317ms/step - accuracy: 0.8462 - loss: 0.3487 - val_accuracy: 0.8457 - val_loss: 0.3503\n",
            "Epoch 3/50\n",
            "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 287ms/step - accuracy: 0.8768 - loss: 0.2828 - val_accuracy: 0.8480 - val_loss: 0.3572\n",
            "Epoch 4/50\n",
            "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 276ms/step - accuracy: 0.8970 - loss: 0.2479 - val_accuracy: 0.8472 - val_loss: 0.3670\n",
            "Epoch 5/50\n",
            "\u001b[1m1167/1167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 268ms/step - accuracy: 0.9259 - loss: 0.1802 - val_accuracy: 0.8469 - val_loss: 0.3870\n",
            "Epoch 1/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 257ms/step - accuracy: 0.6847 - loss: 0.5704 - val_accuracy: 0.8335 - val_loss: 0.3674\n",
            "Epoch 2/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 265ms/step - accuracy: 0.8587 - loss: 0.3324 - val_accuracy: 0.8396 - val_loss: 0.3594\n",
            "Epoch 3/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 261ms/step - accuracy: 0.8723 - loss: 0.2959 - val_accuracy: 0.8423 - val_loss: 0.3504\n",
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 242ms/step - accuracy: 0.6790 - loss: 0.5662 - val_accuracy: 0.8377 - val_loss: 0.3669\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 253ms/step - accuracy: 0.8474 - loss: 0.3465 - val_accuracy: 0.8419 - val_loss: 0.3501\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 246ms/step - accuracy: 0.8770 - loss: 0.2902 - val_accuracy: 0.8427 - val_loss: 0.3665\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 302ms/step - accuracy: 0.8935 - loss: 0.2451 - val_accuracy: 0.8461 - val_loss: 0.3817\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 306ms/step - accuracy: 0.9272 - loss: 0.1765 - val_accuracy: 0.8423 - val_loss: 0.4547\n",
            "Epoch 1/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 416ms/step - accuracy: 0.6925 - loss: 0.5552 - val_accuracy: 0.8305 - val_loss: 0.3712\n",
            "Epoch 2/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 391ms/step - accuracy: 0.8593 - loss: 0.3321 - val_accuracy: 0.8469 - val_loss: 0.3546\n",
            "Epoch 3/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 356ms/step - accuracy: 0.8780 - loss: 0.2816 - val_accuracy: 0.8461 - val_loss: 0.3461\n",
            "Epoch 4/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 351ms/step - accuracy: 0.9067 - loss: 0.2291 - val_accuracy: 0.8370 - val_loss: 0.3838\n",
            "Epoch 5/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 418ms/step - accuracy: 0.9334 - loss: 0.1568 - val_accuracy: 0.8282 - val_loss: 0.4584\n",
            "Epoch 6/50\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 396ms/step - accuracy: 0.9550 - loss: 0.1164 - val_accuracy: 0.8366 - val_loss: 0.4960\n",
            "Epoch 1/50\n",
            "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 405ms/step - accuracy: 0.6806 - loss: 0.5628 - val_accuracy: 0.8309 - val_loss: 0.3716\n",
            "Epoch 2/50\n",
            "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 309ms/step - accuracy: 0.8509 - loss: 0.3479 - val_accuracy: 0.8389 - val_loss: 0.3582\n",
            "Epoch 3/50\n",
            "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 311ms/step - accuracy: 0.8781 - loss: 0.2784 - val_accuracy: 0.8472 - val_loss: 0.3506\n",
            "   lr 0.001\n",
            "9  0.846857\n",
            "8  0.842286\n",
            "7  0.842286\n",
            "6  0.836571\n",
            "5  0.847238\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of learning rates and batch sizes to experiment with\n",
        "learning_rates = [0.001]\n",
        "batch_sizes = [9, 8, 7, 6, 5]\n",
        "\n",
        "# Create a table to store val_accuracy results\n",
        "val_accuracy_table = pd.DataFrame(index=batch_sizes, columns=[f\"lr {lr}\" for lr in learning_rates])\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Loop through learning rates\n",
        "for lr in learning_rates:\n",
        "    # Loop through batch sizes\n",
        "    for batch_size in batch_sizes:\n",
        "        # Create and compile the model with specified learning rate and batch size\n",
        "        model_combined = Sequential()\n",
        "        hidden_size = model_indobertweet.config.hidden_size\n",
        "        model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "        model_combined.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "        model_combined.add(Dropout(0.5))\n",
        "        model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "        model_combined.add(MaxPooling1D(pool_size=2))\n",
        "        model_combined.add(Flatten())\n",
        "        model_combined.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "        optimizer = Adam(learning_rate=lr)\n",
        "        model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        history = model_combined.fit(X_train, y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "        # Save val_accuracy in the table\n",
        "        val_accuracy_table.loc[batch_size, f\"lr {lr}\"] = history.history['val_accuracy'][-1]\n",
        "\n",
        "# Display the val_accuracy table\n",
        "print(val_accuracy_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjC0d9PMi8MA"
      },
      "source": [
        "#**Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3456a22a3ed04c3cb707db2159d028aa",
            "2c2454de6e784576b69ecb99b443f16c",
            "0a917af539be4bbda08169ecf9cb6d6d",
            "6ff30a7d08d14d09b695ecba1c927b73",
            "bb780acea9b6418e91c4a36b1227db14",
            "03447870a07542f5be87a970389e423a",
            "1db3782c489946a0a07287419b84dc03",
            "0fef9a89b4024145a1488cb8c38f2dda",
            "3d0ec305dd47463fb526461cf2822952",
            "50a774f5888243df9b907e2354900d59",
            "6ff23deb28c24cfbb04d3684c0b316c6",
            "7e4b2ce3f4144ef7863ebb472ac6b1e1",
            "85a224df6ec14bf8a89e2f379bd8251c",
            "51446b8e1ff64dbfb529ce7e37ddda3b",
            "e42410aeba2040c59519545512267334",
            "af7140ea16c54d0bb2f64783266027cb",
            "0f4637819ecc4b17b8a1a5610fdf9e36",
            "8eab1147aa6c42d695ecae3e3f818c38",
            "0d86a47dc58a495c89cf2e07d904a697",
            "e8b2cd8e00174857832fbbfa4c7fb4bc",
            "773fc04ba40d4bd184b4006eacb08c4a",
            "8a968cad5a5f428b812a09e82202c33b",
            "9e0a06cd16844ae0afeafc52cc083c5f",
            "1605de02e1dd4f2ab5e9dc84a8defce8",
            "7608fdc7e7a54e96898d0be41e726f8b",
            "4449b3440af1490eaa16b7e474ae4528",
            "fc03912393ad491d8b46079b72196d8b",
            "45fb0e23d14942e9a13a9db4b921796d",
            "846ac2edcc404ede87c441889c5c1245",
            "8d1c44ea836e4d01b0067990714d5a1f",
            "b7ff1dfd18634dddafcd6c219194679e",
            "094f91ff22dd4f66bf11e6e1ebc9c8b1",
            "757286d4e0b64333881c3d646a7f16ad",
            "75a7a725b2c44c8db92a6e14e5b9e4b6",
            "4b134e79a411423bbd245eac39a665f9",
            "d4dbf12ab76d44e2bd61689710f8b6c5",
            "03314b11500a4550878daf610304a4d1",
            "7bd8a8c10d4b436f81861d17f8d458ea",
            "2fe92f1cff1b4f9ba3040dd334fa8570",
            "a317e7fcdc3c4f999aaf59fccd2b80e0",
            "ccc1c1794c964395aa26f359eaed5072",
            "a81fcffeaad24f9a94ebaa42f2b24b7b",
            "8fc7002eb82344ec9fc9bc58c378cefb",
            "d10ceb4c86cd42cbbb8f7ef6ce1634d5",
            "76d54c56c0d84d779fd8d66558f584f6",
            "be75b44d6ea645009e1b364f579b6c3f",
            "009334a14528412fa46ad790103bbabb",
            "e5b47341e9e04475aa7c312861031cac",
            "b0dfbdade7a54c9aae25a943f8ceb4fe",
            "37a2bf09dd2240c7830388d06ada8e1b",
            "394953efd80f4ec49a69a939a9f8fc5b",
            "ff5fbcb4f4554976888fb98d54ae2df7",
            "166411f953bf4535b7661f0c3bcc1397",
            "078519d3e4ca4ed9a0c6b74d2e595680",
            "082f42c7bb2e4db6811cb7591a64b946"
          ]
        },
        "id": "MMs2StDlZA5Z",
        "outputId": "ec6d4b92-ed15-458b-9e7e-f3bb20524276"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_24                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_24                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_24 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_18 (\u001b[38;5;33mFlatten\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 151ms/step - accuracy: 0.6127 - loss: 0.6392 - val_accuracy: 0.8179 - val_loss: 0.4066\n",
            "Epoch 2/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 150ms/step - accuracy: 0.8212 - loss: 0.3989 - val_accuracy: 0.8202 - val_loss: 0.3936\n",
            "Epoch 3/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 150ms/step - accuracy: 0.8503 - loss: 0.3386 - val_accuracy: 0.8343 - val_loss: 0.3646\n",
            "Epoch 4/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 149ms/step - accuracy: 0.8718 - loss: 0.2985 - val_accuracy: 0.8495 - val_loss: 0.3456\n",
            "Epoch 5/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 158ms/step - accuracy: 0.8907 - loss: 0.2598 - val_accuracy: 0.8385 - val_loss: 0.3813\n",
            "Epoch 6/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 158ms/step - accuracy: 0.9017 - loss: 0.2315 - val_accuracy: 0.8457 - val_loss: 0.3674\n",
            "Epoch 7/50\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 152ms/step - accuracy: 0.9211 - loss: 0.1964 - val_accuracy: 0.8446 - val_loss: 0.3774\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8684    0.8689    0.8686      1503\n",
            "           1     0.8243    0.8235    0.8239      1122\n",
            "\n",
            "    accuracy                         0.8495      2625\n",
            "   macro avg     0.8463    0.8462    0.8463      2625\n",
            "weighted avg     0.8495    0.8495    0.8495      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(32, kernel_size=5, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_44\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_44\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_31                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_31 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_31                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_31 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_25 (\u001b[38;5;33mFlatten\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 117ms/step - accuracy: 0.6514 - loss: 0.6051 - val_accuracy: 0.8293 - val_loss: 0.3921\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 113ms/step - accuracy: 0.8403 - loss: 0.3583 - val_accuracy: 0.8385 - val_loss: 0.3595\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 116ms/step - accuracy: 0.8647 - loss: 0.3039 - val_accuracy: 0.8392 - val_loss: 0.3538\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 115ms/step - accuracy: 0.8788 - loss: 0.2783 - val_accuracy: 0.8507 - val_loss: 0.3519\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 116ms/step - accuracy: 0.9025 - loss: 0.2319 - val_accuracy: 0.8438 - val_loss: 0.3781\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 116ms/step - accuracy: 0.9175 - loss: 0.1941 - val_accuracy: 0.8358 - val_loss: 0.4497\n",
            "Epoch 7/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 117ms/step - accuracy: 0.9393 - loss: 0.1542 - val_accuracy: 0.8267 - val_loss: 0.5237\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8781    0.8583    0.8681      1503\n",
            "           1     0.8157    0.8405    0.8279      1122\n",
            "\n",
            "    accuracy                         0.8507      2625\n",
            "   macro avg     0.8469    0.8494    0.8480      2625\n",
            "weighted avg     0.8515    0.8507    0.8509      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(64, kernel_size=3, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_18                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_18                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_18 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 379ms/step - accuracy: 0.6229 - loss: 0.6283 - val_accuracy: 0.8194 - val_loss: 0.3856\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 357ms/step - accuracy: 0.8442 - loss: 0.3468 - val_accuracy: 0.8370 - val_loss: 0.3612\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 321ms/step - accuracy: 0.8701 - loss: 0.3023 - val_accuracy: 0.8499 - val_loss: 0.3433\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 276ms/step - accuracy: 0.8932 - loss: 0.2523 - val_accuracy: 0.8434 - val_loss: 0.3676\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 276ms/step - accuracy: 0.9089 - loss: 0.2156 - val_accuracy: 0.8373 - val_loss: 0.3799\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 291ms/step - accuracy: 0.9309 - loss: 0.1647 - val_accuracy: 0.8385 - val_loss: 0.5172\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8679    0.8703    0.8691      1503\n",
            "           1     0.8256    0.8226    0.8241      1122\n",
            "\n",
            "    accuracy                         0.8499      2625\n",
            "   macro avg     0.8468    0.8464    0.8466      2625\n",
            "weighted avg     0.8498    0.8499    0.8499      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_53\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_53\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_40                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_43 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_40                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_40 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_28 (\u001b[38;5;33mFlatten\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 398ms/step - accuracy: 0.6848 - loss: 0.5731 - val_accuracy: 0.8229 - val_loss: 0.3860\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 376ms/step - accuracy: 0.8443 - loss: 0.3521 - val_accuracy: 0.8354 - val_loss: 0.3569\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 394ms/step - accuracy: 0.8736 - loss: 0.2966 - val_accuracy: 0.8453 - val_loss: 0.3514\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 387ms/step - accuracy: 0.8908 - loss: 0.2572 - val_accuracy: 0.8545 - val_loss: 0.3473\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 350ms/step - accuracy: 0.9105 - loss: 0.2111 - val_accuracy: 0.8427 - val_loss: 0.4259\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 413ms/step - accuracy: 0.9360 - loss: 0.1680 - val_accuracy: 0.8404 - val_loss: 0.4156\n",
            "Epoch 7/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 408ms/step - accuracy: 0.9561 - loss: 0.1144 - val_accuracy: 0.8381 - val_loss: 0.5465\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8623    0.8876    0.8748      1503\n",
            "           1     0.8432    0.8102    0.8264      1122\n",
            "\n",
            "    accuracy                         0.8545      2625\n",
            "   macro avg     0.8528    0.8489    0.8506      2625\n",
            "weighted avg     0.8542    0.8545    0.8541      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "model_combined.save('model_final.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 280ms/step - accuracy: 0.6429 - loss: 0.6052 - val_accuracy: 0.8244 - val_loss: 0.3911\n",
            "Epoch 2/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 335ms/step - accuracy: 0.8402 - loss: 0.3477 - val_accuracy: 0.8427 - val_loss: 0.3527\n",
            "Epoch 3/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 290ms/step - accuracy: 0.8674 - loss: 0.3050 - val_accuracy: 0.8419 - val_loss: 0.3827\n",
            "Epoch 4/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 285ms/step - accuracy: 0.8896 - loss: 0.2597 - val_accuracy: 0.8430 - val_loss: 0.3505\n",
            "Epoch 5/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 210ms/step - accuracy: 0.9058 - loss: 0.2213 - val_accuracy: 0.8415 - val_loss: 0.4294\n",
            "Epoch 6/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 204ms/step - accuracy: 0.9311 - loss: 0.1632 - val_accuracy: 0.8301 - val_loss: 0.4869\n",
            "Epoch 7/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 204ms/step - accuracy: 0.9505 - loss: 0.1318 - val_accuracy: 0.8324 - val_loss: 0.5385\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 179ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8446    0.8896    0.8665      1503\n",
            "           1     0.8407    0.7807    0.8096      1122\n",
            "\n",
            "    accuracy                         0.8430      2625\n",
            "   macro avg     0.8426    0.8352    0.8381      2625\n",
            "weighted avg     0.8429    0.8430    0.8422      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=3))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model_combined.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 111ms/step - accuracy: 0.5644 - loss: 0.6913 - val_accuracy: 0.5726 - val_loss: 0.6826\n",
            "Epoch 2/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 118ms/step - accuracy: 0.5730 - loss: 0.6836 - val_accuracy: 0.5726 - val_loss: 0.6829\n",
            "Epoch 3/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 122ms/step - accuracy: 0.5769 - loss: 0.6830 - val_accuracy: 0.5726 - val_loss: 0.6826\n",
            "Epoch 4/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 106ms/step - accuracy: 0.5781 - loss: 0.6824 - val_accuracy: 0.5726 - val_loss: 0.6826\n",
            "Epoch 5/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 126ms/step - accuracy: 0.5765 - loss: 0.6827 - val_accuracy: 0.5726 - val_loss: 0.6826\n",
            "Epoch 6/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 136ms/step - accuracy: 0.5808 - loss: 0.6813 - val_accuracy: 0.5726 - val_loss: 0.6829\n",
            "Epoch 7/50\n",
            "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 130ms/step - accuracy: 0.5851 - loss: 0.6794 - val_accuracy: 0.5726 - val_loss: 0.6837\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[0;32m     50\u001b[0m y_pred_rnn \u001b[38;5;241m=\u001b[39m model_rnn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 51\u001b[0m y_pred_classes_rnn \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mround(y_pred_rnn)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Classification Report\u001b[39;00m\n\u001b[0;32m     54\u001b[0m class_report_rnn \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred_classes_rnn, digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "# Tokenization using IndoBERTweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load IndoBERTweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the RNN model using the name 'model_rnn'\n",
        "model_rnn = Sequential()\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "model_rnn.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_rnn.add(LSTM(128, return_sequences=False))\n",
        "model_rnn.add(Dropout(0.5))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_rnn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_rnn.summary()\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history_rnn = model_rnn.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Predictions\n",
        "y_pred_rnn = model_rnn.predict(X_test)\n",
        "y_pred_classes_rnn = np.round(y_pred_rnn)\n",
        "\n",
        "# Classification Report\n",
        "class_report_rnn = classification_report(y_test, y_pred_classes_rnn, digits=4)\n",
        "print(\"Classification Report for RNN Model:\")\n",
        "print(class_report_rnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "lineplot() takes from 0 to 1 positional arguments but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 1 row, 2 columns, 1st subplot\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and Validation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: lineplot() takes from 0 to 1 positional arguments but 2 were given"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf  # Jika Anda menggunakan TensorFlow untuk pelatihan model\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
        "sns.lineplot(range(1, len(history.history['loss']) + 1), history.history['loss'], label='Train Loss')\n",
        "sns.lineplot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting the training and validation accuracy\n",
        "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
        "sns.lineplot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'], label='Train Accuracy')\n",
        "sns.lineplot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_56\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_56\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_43                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_46 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_43                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_43 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_31 (\u001b[38;5;33mFlatten\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 247ms/step - accuracy: 0.6987 - loss: 0.5557 - val_accuracy: 0.8217 - val_loss: 0.3927\n",
            "Epoch 2/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 247ms/step - accuracy: 0.8465 - loss: 0.3438 - val_accuracy: 0.8465 - val_loss: 0.3484\n",
            "Epoch 3/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 254ms/step - accuracy: 0.8720 - loss: 0.2945 - val_accuracy: 0.8430 - val_loss: 0.3658\n",
            "Epoch 4/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 274ms/step - accuracy: 0.8917 - loss: 0.2522 - val_accuracy: 0.8373 - val_loss: 0.3699\n",
            "Epoch 5/50\n",
            "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 238ms/step - accuracy: 0.9212 - loss: 0.1881 - val_accuracy: 0.8476 - val_loss: 0.4166\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8387    0.9062    0.8711      1503\n",
            "           1     0.8591    0.7665    0.8102      1122\n",
            "\n",
            "    accuracy                         0.8465      2625\n",
            "   macro avg     0.8489    0.8363    0.8406      2625\n",
            "weighted avg     0.8474    0.8465    0.8451      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined8 = Sequential()\n",
        "model_combined8.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined8.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model_combined8.add(Dropout(0.5))\n",
        "model_combined8.add(Conv1D(128, kernel_size=5, padding='valid', activation='relu'))\n",
        "model_combined8.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined8.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined8.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined8.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined8.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined8.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined8.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_19                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_22 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │    \u001b[38;5;34m24,516,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_19                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_19 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,516,864</span> (93.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,516,864\u001b[0m (93.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 197ms/step - accuracy: 0.6403 - loss: 0.6102 - val_accuracy: 0.8301 - val_loss: 0.3939\n",
            "Epoch 2/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 152ms/step - accuracy: 0.8439 - loss: 0.3518 - val_accuracy: 0.8366 - val_loss: 0.3611\n",
            "Epoch 3/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 137ms/step - accuracy: 0.8717 - loss: 0.3024 - val_accuracy: 0.8225 - val_loss: 0.3980\n",
            "Epoch 4/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 140ms/step - accuracy: 0.8826 - loss: 0.2779 - val_accuracy: 0.8495 - val_loss: 0.3585\n",
            "Epoch 5/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 159ms/step - accuracy: 0.9024 - loss: 0.2404 - val_accuracy: 0.8404 - val_loss: 0.4141\n",
            "Epoch 6/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 129ms/step - accuracy: 0.9186 - loss: 0.1950 - val_accuracy: 0.8350 - val_loss: 0.3873\n",
            "Epoch 7/50\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 139ms/step - accuracy: 0.9444 - loss: 0.1424 - val_accuracy: 0.8442 - val_loss: 0.4307\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8366    0.9162    0.8746      1503\n",
            "           1     0.8713    0.7602    0.8120      1122\n",
            "\n",
            "    accuracy                         0.8495      2625\n",
            "   macro avg     0.8539    0.8382    0.8433      2625\n",
            "weighted avg     0.8514    0.8495    0.8478      2625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Tokenization using Indobertweet tokenizer\n",
        "max_len = 100\n",
        "tokenizer_indobertweet = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "sequences_indobertweet = tokenizer_indobertweet(df['no_stopwords'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "X_indobertweet = pad_sequences(sequences_indobertweet['input_ids'], maxlen=max_len, padding='post')\n",
        "\n",
        "# Load Indobertweet model with from_pt=True\n",
        "model_indobertweet = TFAutoModel.from_pretrained(\"indolem/indobertweet-base-uncased\", from_pt=True)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "df['HS'] = le.fit_transform(df['HS'])\n",
        "y = df['HS'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_indobertweet, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace the feedforward layer with BiLSTM and CNN layers\n",
        "model_combined = Sequential()\n",
        "\n",
        "# Get the hidden size directly from the model\n",
        "hidden_size = model_indobertweet.config.hidden_size\n",
        "\n",
        "\n",
        "# Define the improved model using the name 'model_combined'\n",
        "model_combined = Sequential()\n",
        "model_combined.add(Embedding(input_dim=tokenizer_indobertweet.vocab_size, output_dim=hidden_size, input_length=max_len, weights=[model_indobertweet.get_weights()[0]], trainable=False))\n",
        "model_combined.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model_combined.add(Dropout(0.5))\n",
        "model_combined.add(Conv1D(64, kernel_size=3, padding='valid', activation='relu'))\n",
        "model_combined.add(MaxPooling1D(pool_size=2))\n",
        "#model_combined.add(Conv1D(32, kernel_size=3, padding='valid', activation='relu'))\n",
        "#model_combined.add(MaxPooling1D(pool_size=2))\n",
        "model_combined.add(Flatten())\n",
        "#model_combined.add(Dense(128, activation='relu'))\n",
        "#model_combined.add(Dropout(0.5))\n",
        "#model_combined.add(Dense(64, activation='relu'))\n",
        "model_combined.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_combined.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_combined.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model_combined.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model_combined.predict(X_test)\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred_classes, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzGow1iqkKpd"
      },
      "source": [
        "#**Simple Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ifs33bbq1Tf",
        "outputId": "2a90573a-b9b0-44c3-eb44-ae19c3787290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "Detection Result: Not Hate Speech\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Detection Result: Hate Speech Detected\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Detection Result: Not Hate Speech\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobertweet-base-uncased\")\n",
        "\n",
        "# Load the model\n",
        "model = model_combined#load_model('trained_model.h5')  # Make sure the model path is correct\n",
        "\n",
        "def detect_hate_speech(text):\n",
        "    # Tokenize and prepare the input text\n",
        "    max_len = 100\n",
        "    tokens = tokenizer.encode_plus(text, max_length=max_len, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')\n",
        "    input_ids = tokens['input_ids']\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_ids)[0]\n",
        "\n",
        "    # Determine the class based on the model's prediction\n",
        "    hate_speech_probability = prediction[0]\n",
        "    if hate_speech_probability > 0.5:\n",
        "        result = \"Hate Speech Detected\"\n",
        "    else:\n",
        "        result = \"Not Hate Speech\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example use\n",
        "while True:\n",
        "    text = input(\"Teks : \")\n",
        "    result = detect_hate_speech(text)\n",
        "    print(f\"Detection Result: {result}\")\n",
        "    lanjut = input(\"input lagi? y/n : \")\n",
        "    if lanjut == \"y\":\n",
        "        True\n",
        "    else:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009334a14528412fa46ad790103bbabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5fbcb4f4554976888fb98d54ae2df7",
            "max": 444780374,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_166411f953bf4535b7661f0c3bcc1397",
            "value": 444780374
          }
        },
        "03314b11500a4550878daf610304a4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc7002eb82344ec9fc9bc58c378cefb",
            "placeholder": "​",
            "style": "IPY_MODEL_d10ceb4c86cd42cbbb8f7ef6ce1634d5",
            "value": " 112/112 [00:00&lt;00:00, 7.84kB/s]"
          }
        },
        "03447870a07542f5be87a970389e423a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078519d3e4ca4ed9a0c6b74d2e595680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082f42c7bb2e4db6811cb7591a64b946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "094f91ff22dd4f66bf11e6e1ebc9c8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a917af539be4bbda08169ecf9cb6d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fef9a89b4024145a1488cb8c38f2dda",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d0ec305dd47463fb526461cf2822952",
            "value": 2
          }
        },
        "0d86a47dc58a495c89cf2e07d904a697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4637819ecc4b17b8a1a5610fdf9e36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fef9a89b4024145a1488cb8c38f2dda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1605de02e1dd4f2ab5e9dc84a8defce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45fb0e23d14942e9a13a9db4b921796d",
            "placeholder": "​",
            "style": "IPY_MODEL_846ac2edcc404ede87c441889c5c1245",
            "value": "vocab.txt: 100%"
          }
        },
        "166411f953bf4535b7661f0c3bcc1397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1db3782c489946a0a07287419b84dc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2454de6e784576b69ecb99b443f16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03447870a07542f5be87a970389e423a",
            "placeholder": "​",
            "style": "IPY_MODEL_1db3782c489946a0a07287419b84dc03",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2fe92f1cff1b4f9ba3040dd334fa8570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3456a22a3ed04c3cb707db2159d028aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c2454de6e784576b69ecb99b443f16c",
              "IPY_MODEL_0a917af539be4bbda08169ecf9cb6d6d",
              "IPY_MODEL_6ff30a7d08d14d09b695ecba1c927b73"
            ],
            "layout": "IPY_MODEL_bb780acea9b6418e91c4a36b1227db14"
          }
        },
        "37a2bf09dd2240c7830388d06ada8e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394953efd80f4ec49a69a939a9f8fc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d0ec305dd47463fb526461cf2822952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4449b3440af1490eaa16b7e474ae4528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094f91ff22dd4f66bf11e6e1ebc9c8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_757286d4e0b64333881c3d646a7f16ad",
            "value": " 235k/235k [00:00&lt;00:00, 7.17MB/s]"
          }
        },
        "45fb0e23d14942e9a13a9db4b921796d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b134e79a411423bbd245eac39a665f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe92f1cff1b4f9ba3040dd334fa8570",
            "placeholder": "​",
            "style": "IPY_MODEL_a317e7fcdc3c4f999aaf59fccd2b80e0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "50a774f5888243df9b907e2354900d59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51446b8e1ff64dbfb529ce7e37ddda3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d86a47dc58a495c89cf2e07d904a697",
            "max": 1101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8b2cd8e00174857832fbbfa4c7fb4bc",
            "value": 1101
          }
        },
        "6ff23deb28c24cfbb04d3684c0b316c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff30a7d08d14d09b695ecba1c927b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a774f5888243df9b907e2354900d59",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff23deb28c24cfbb04d3684c0b316c6",
            "value": " 2.00/2.00 [00:00&lt;00:00, 134B/s]"
          }
        },
        "757286d4e0b64333881c3d646a7f16ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a7a725b2c44c8db92a6e14e5b9e4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b134e79a411423bbd245eac39a665f9",
              "IPY_MODEL_d4dbf12ab76d44e2bd61689710f8b6c5",
              "IPY_MODEL_03314b11500a4550878daf610304a4d1"
            ],
            "layout": "IPY_MODEL_7bd8a8c10d4b436f81861d17f8d458ea"
          }
        },
        "7608fdc7e7a54e96898d0be41e726f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1c44ea836e4d01b0067990714d5a1f",
            "max": 235395,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7ff1dfd18634dddafcd6c219194679e",
            "value": 235395
          }
        },
        "76d54c56c0d84d779fd8d66558f584f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be75b44d6ea645009e1b364f579b6c3f",
              "IPY_MODEL_009334a14528412fa46ad790103bbabb",
              "IPY_MODEL_e5b47341e9e04475aa7c312861031cac"
            ],
            "layout": "IPY_MODEL_b0dfbdade7a54c9aae25a943f8ceb4fe"
          }
        },
        "773fc04ba40d4bd184b4006eacb08c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd8a8c10d4b436f81861d17f8d458ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4b2ce3f4144ef7863ebb472ac6b1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85a224df6ec14bf8a89e2f379bd8251c",
              "IPY_MODEL_51446b8e1ff64dbfb529ce7e37ddda3b",
              "IPY_MODEL_e42410aeba2040c59519545512267334"
            ],
            "layout": "IPY_MODEL_af7140ea16c54d0bb2f64783266027cb"
          }
        },
        "846ac2edcc404ede87c441889c5c1245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a224df6ec14bf8a89e2f379bd8251c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4637819ecc4b17b8a1a5610fdf9e36",
            "placeholder": "​",
            "style": "IPY_MODEL_8eab1147aa6c42d695ecae3e3f818c38",
            "value": "config.json: 100%"
          }
        },
        "8a968cad5a5f428b812a09e82202c33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d1c44ea836e4d01b0067990714d5a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eab1147aa6c42d695ecae3e3f818c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fc7002eb82344ec9fc9bc58c378cefb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0a06cd16844ae0afeafc52cc083c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1605de02e1dd4f2ab5e9dc84a8defce8",
              "IPY_MODEL_7608fdc7e7a54e96898d0be41e726f8b",
              "IPY_MODEL_4449b3440af1490eaa16b7e474ae4528"
            ],
            "layout": "IPY_MODEL_fc03912393ad491d8b46079b72196d8b"
          }
        },
        "a317e7fcdc3c4f999aaf59fccd2b80e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a81fcffeaad24f9a94ebaa42f2b24b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7140ea16c54d0bb2f64783266027cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0dfbdade7a54c9aae25a943f8ceb4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ff1dfd18634dddafcd6c219194679e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb780acea9b6418e91c4a36b1227db14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be75b44d6ea645009e1b364f579b6c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a2bf09dd2240c7830388d06ada8e1b",
            "placeholder": "​",
            "style": "IPY_MODEL_394953efd80f4ec49a69a939a9f8fc5b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "ccc1c1794c964395aa26f359eaed5072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10ceb4c86cd42cbbb8f7ef6ce1634d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4dbf12ab76d44e2bd61689710f8b6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc1c1794c964395aa26f359eaed5072",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a81fcffeaad24f9a94ebaa42f2b24b7b",
            "value": 112
          }
        },
        "e42410aeba2040c59519545512267334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773fc04ba40d4bd184b4006eacb08c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_8a968cad5a5f428b812a09e82202c33b",
            "value": " 1.10k/1.10k [00:00&lt;00:00, 65.9kB/s]"
          }
        },
        "e5b47341e9e04475aa7c312861031cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078519d3e4ca4ed9a0c6b74d2e595680",
            "placeholder": "​",
            "style": "IPY_MODEL_082f42c7bb2e4db6811cb7591a64b946",
            "value": " 445M/445M [00:05&lt;00:00, 79.7MB/s]"
          }
        },
        "e8b2cd8e00174857832fbbfa4c7fb4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc03912393ad491d8b46079b72196d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5fbcb4f4554976888fb98d54ae2df7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
